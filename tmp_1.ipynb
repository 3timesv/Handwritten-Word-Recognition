{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tmp_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekverma1019/Handwritten-Word-Recognition/blob/master/tmp_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2goBigMqKMNd",
        "colab_type": "code",
        "outputId": "af73fcf6-771e-4cc4-f8dd-74aef14c3c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiGPyvXNg_4",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessor.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6W_Nb4Iyjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def add_padding(img, old_w, old_h, new_w, new_h):\n",
        "    h1, h2 = int((new_h-old_h)/2), int((new_h-old_h)/2)+old_h\n",
        "    w1, w2 = int((new_w-old_w)/2), int((new_w-old_w)/2)+old_w\n",
        "    img_pad = np.ones([new_h, new_w, 3]) * 255\n",
        "    img_pad[h1:h2, w1:w2,:] = img\n",
        "    return img_pad\n",
        "\n",
        "def fix_size(img, target_w, target_h):\n",
        "    h, w = img.shape[:2]\n",
        "    if w<target_w and h<target_h:\n",
        "        img = add_padding(img, w, h, target_w, target_h)\n",
        "    elif w>=target_w and h<target_h:\n",
        "        new_w = target_w\n",
        "        new_h = int(h*new_w/w)\n",
        "        new_img = cv.resize(img, (new_w, new_h), interpolation = cv.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    elif w<target_w and h>=target_h:\n",
        "        new_h = target_h\n",
        "        new_w = int(w*new_h/h)\n",
        "        new_img = cv.resize(img, (new_w, new_h), interpolation = cv.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    else:\n",
        "        '''w>=target_w and h>=target_h '''\n",
        "        ratio = max(w/target_w, h/target_h)\n",
        "        new_w = max(min(target_w, int(w / ratio)), 1)\n",
        "        new_h = max(min(target_h, int(h / ratio)), 1)\n",
        "        new_img = cv.resize(img, (new_w, new_h), interpolation = cv.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    return img\n",
        "\n",
        "def preprocess(path, img_w, img_h):\n",
        "    \"\"\" Pre-processing image for predicting \"\"\"\n",
        "    img = cv.imread(path)\n",
        "    img = fix_size(img, img_w, img_h)\n",
        "\n",
        "    img = np.clip(img, 0, 255)\n",
        "    img = np.uint8(img)\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "    img = img.astype(np.float32)\n",
        "    img /= 255\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzC9Z6pnNmj_",
        "colab_type": "text"
      },
      "source": [
        "### Paremeter.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7JcdjM5NYhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "letters = [' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "num_classes = len(letters) + 1\n",
        "img_h = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvb9KpHeO1-S",
        "colab_type": "text"
      },
      "source": [
        "### Utils.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFVCwhBsNd11",
        "colab_type": "code",
        "outputId": "3beb51b4-0d93-4937-8cc9-ea8482554e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import itertools\n",
        "#from Parameter import *\n",
        "#from Preprocessor import preprocess\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def decode_label(out):\n",
        "    out_best = list(np.argmax(out[0, 2:], 1))\n",
        "    out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "    outstr = ''\n",
        "    for c in out_best:\n",
        "        if c < len(letters):\n",
        "            outstr += letters[c]\n",
        "    return outstr\n",
        "\n",
        "def decode_batch(out):\n",
        "    ret = []\n",
        "    for j in range(out.shape[0]):\n",
        "        out_best = list(np.argmax(out[j, 2:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = ''\n",
        "        for c in out_best:\n",
        "            if c < len(letters):\n",
        "                outstr += letters[c]\n",
        "        ret.append(outstr)\n",
        "    return ret\n",
        "\n",
        "def get_paths_and_texts(is_words):\n",
        "    paths_and_texts = []\n",
        "    if is_words:\n",
        "        with open('/content/drive/My Drive/Downloads/iam_words/words.txt') as f:\n",
        "            for line in f:\n",
        "                if not line or line.startswith('#'):\n",
        "                    continue\n",
        "                line_split = line.strip().split(' ')\n",
        "                assert len(line_split) >= 9\n",
        "                status = line_split[1]\n",
        "                if status == 'err':\n",
        "                    continue\n",
        "                file_name_split = line_split[0].split('-')\n",
        "                label_dir = file_name_split[0]\n",
        "                sub_label_dir = '{}-{}'.format(file_name_split[0], file_name_split[1])\n",
        "                fn = '{}.png'.format(line_split[0])\n",
        "                img_path = os.path.join('/content/drive/My Drive/Downloads/iam_words/words', label_dir, sub_label_dir, fn)\n",
        "                gt_text = ' '.join(line_split[8:])\n",
        "                paths_and_texts.append([img_path, gt_text])\n",
        "    else:\n",
        "        with open('../IAM_lines/lines.txt') as f:\n",
        "            for line in f:\n",
        "                if not line or line.startswith('#'):\n",
        "                    continue\n",
        "                line_split = line.strip().split(' ')\n",
        "                assert len(line_split) >= 9\n",
        "                status = line_split[1]\n",
        "                if status == 'err':\n",
        "                    continue\n",
        "                file_name_split = line_split[0].split('-')\n",
        "                label_dir = file_name_split[0]\n",
        "                sub_label_dir = '{}-{}'.format(file_name_split[0], file_name_split[1])\n",
        "                fn = '{}.png'.format(line_split[0])\n",
        "                img_path = os.path.join('../IAM_lines/lines', label_dir, sub_label_dir, fn)\n",
        "                gt_text = ' '.join(line_split[8:])\n",
        "                gt_text = gt_text.replace('|', ' ')\n",
        "                l = len(gt_text)\n",
        "                if l<10 or l>74:\n",
        "                    continue\n",
        "                paths_and_texts.append([img_path, gt_text])\n",
        "    return paths_and_texts\n",
        "\n",
        "def predict_image(model_predict, path, is_word):\n",
        "    if is_word:\n",
        "        width = 128\n",
        "    else:\n",
        "        width = 800\n",
        "    img = preprocess(path, width, 64)\n",
        "    img = img.T\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        img = np.expand_dims(img, 0)\n",
        "    else:\n",
        "        img = np.expand_dims(img, -1)\n",
        "    img = np.expand_dims(img, 0)\n",
        "\n",
        "    net_out_value = model_predict.predict(img)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    return pred_texts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-27AIrCS1hA",
        "colab_type": "text"
      },
      "source": [
        "### CRNN_Model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkNkeTC2R_84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation, Reshape, Lambda, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.layers.merge import add, concatenate\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "def word_model():\n",
        "    img_w = 128\n",
        "    img_h = 64\n",
        "    max_text_len = 16\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (1, img_w, img_h)\n",
        "    else:\n",
        "        input_shape = (img_w, img_h, 1)\n",
        "\n",
        "    # Make Networkw\n",
        "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)\n",
        "\n",
        "    # Convolution layer (VGG)\n",
        "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  # (None, 128, 64, 64)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
        "\n",
        "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
        "\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
        "\n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
        "\n",
        "    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "\n",
        "    # CNN to RNN\n",
        "    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
        "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
        "\n",
        "    # RNN layer\n",
        "    gru_1 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)  # (None, 32, 512)\n",
        "    gru_1b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "    reversed_gru_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (gru_1b)\n",
        "\n",
        "    gru1_merged = add([gru_1, reversed_gru_1b])  # (None, 32, 512)\n",
        "    gru1_merged = BatchNormalization()(gru1_merged)\n",
        "    \n",
        "    gru_2 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "    gru_2b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "    reversed_gru_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (gru_2b)\n",
        "\n",
        "    gru2_merged = concatenate([gru_2, reversed_gru_2b])  # (None, 32, 1024)\n",
        "    gru2_merged = BatchNormalization()(gru2_merged)\n",
        "\n",
        "    # transforms RNN output to character activations:\n",
        "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(gru2_merged) #(None, 32, 80)\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "    # loss function\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
        "        [y_pred, labels, input_length, label_length]\n",
        "    )\n",
        "\n",
        "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "    model_predict = Model(inputs=input_data, outputs=y_pred)\n",
        "    model_predict.summary()\n",
        "\n",
        "    return model, model_predict\n",
        "\n",
        "\n",
        "def line_model():\n",
        "    img_w = 800\n",
        "    max_text_len = 74\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (1, img_w, img_h)\n",
        "    else:\n",
        "        input_shape = (img_w, img_h, 1)\n",
        "\n",
        "    # Make Networkw\n",
        "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 800, 64, 1)\n",
        "\n",
        "    # Convolution layer\n",
        "    inner = Conv2D(64, (5, 5), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  # (None, 800, 64, 64)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,400, 32, 64)\n",
        "\n",
        "    inner = Conv2D(128, (5, 5), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 400, 32, 128)\n",
        "    inner = Activation('relu')(inner)\n",
        "\n",
        "    inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 400, 32, 128)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 200, 16, 128)\n",
        "    \n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 200, 16, 256)\n",
        "    inner = Activation('relu')(inner)\n",
        "    \n",
        "    inner = Conv2D(256, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 200, 16, 256)\n",
        "    inner = Activation('relu')(inner)\n",
        "    \n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv6', kernel_initializer='he_normal')(inner)  # (None, 200, 16, 512)\n",
        "    inner = BatchNormalization()(inner)\n",
        "    inner = Activation('relu')(inner)\n",
        "    \n",
        "    inner = Conv2D(512, (3, 3), padding='same', name='conv7', kernel_initializer='he_normal')(inner)  # (None, 200, 16, 512)\n",
        "    inner = Activation('relu')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max3')(inner)  # (None, 100, 8, 512)\n",
        "\n",
        "    # CNN to RNN\n",
        "    inner = Reshape(target_shape=((100, 4096)), name='reshape')(inner)  # (None, 100, 4096)\n",
        "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 100, 64)\n",
        "\n",
        "    # RNN layer\n",
        "    gru_1 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)  # (None, 100, 512)\n",
        "    gru_1b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "    reversed_gru_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (gru_1b)\n",
        "\n",
        "    gru1_merged = add([gru_1, reversed_gru_1b])  # (None, 100, 512)\n",
        "    gru1_merged = BatchNormalization()(gru1_merged)\n",
        "    \n",
        "    gru_2 = GRU(256, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "    gru_2b = GRU(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "    reversed_gru_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (gru_2b)\n",
        "\n",
        "    gru2_merged = concatenate([gru_2, reversed_gru_2b])  # (None, 100, 1024)\n",
        "    gru2_merged = BatchNormalization()(gru2_merged)\n",
        "\n",
        "    # transforms RNN output to character activations:\n",
        "    inner = Dense(80, kernel_initializer='he_normal',name='dense2')(gru2_merged) #(None, 100, 80)\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "    # loss function\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
        "        [y_pred, labels, input_length, label_length]\n",
        "    )\n",
        "\n",
        "    model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "    model_predict = Model(inputs=input_data, outputs=y_pred)\n",
        "    model_predict.summary()\n",
        "\n",
        "    return model, model_predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7WJTlf4TGax",
        "colab_type": "text"
      },
      "source": [
        "### ImageGenerator.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIsu7B8AS9_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from keras import backend as K\n",
        "#from Preprocessor import preprocess\n",
        "#from Parameter import *\n",
        "\n",
        "\n",
        "def labels_to_text(labels):\n",
        "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
        "\n",
        "def text_to_labels(text):\n",
        "    return list(map(lambda x: letters.index(x), text))\n",
        "\n",
        "class TextImageGenerator:\n",
        "    \n",
        "    def __init__(self, data,\n",
        "                 img_w,\n",
        "                 img_h, \n",
        "                 batch_size, \n",
        "                 i_len,\n",
        "                 max_text_len):\n",
        "        \n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.batch_size = batch_size\n",
        "        self.max_text_len = max_text_len\n",
        "        self.samples = data\n",
        "        self.n = len(self.samples)\n",
        "        self.i_len = i_len\n",
        "        self.indexes = list(range(self.n))\n",
        "        self.cur_index = 0\n",
        "        \n",
        "    def build_data(self):\n",
        "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
        "        self.texts = []\n",
        "        for i, (img_filepath, text) in enumerate(self.samples):\n",
        "            img = preprocess(img_filepath, self.img_w, self.img_h)\n",
        "            self.imgs[i, :, :] = img\n",
        "            self.texts.append(text)\n",
        "    \n",
        "    def next_sample(self):\n",
        "        self.cur_index += 1\n",
        "        if self.cur_index >= self.n:\n",
        "            self.cur_index = 0\n",
        "            random.shuffle(self.indexes)\n",
        "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
        "    \n",
        "    def next_batch(self):\n",
        "        while True:\n",
        "            # width and height are backwards from typical Keras convention\n",
        "            # because width is the time dimension when it gets fed into the RNN\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                X_data = np.ones([self.batch_size, 1, self.img_w, self.img_h])\n",
        "            else:\n",
        "                X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
        "            Y_data = np.zeros([self.batch_size, self.max_text_len])\n",
        "            input_length = np.ones((self.batch_size, 1)) * self.i_len\n",
        "            label_length = np.zeros((self.batch_size, 1))\n",
        "                                   \n",
        "            for i in range(self.batch_size):\n",
        "                img, text = self.next_sample()\n",
        "                img = img.T\n",
        "                if K.image_data_format() == 'channels_first':\n",
        "                    img = np.expand_dims(img, 0)\n",
        "                else:\n",
        "                    img = np.expand_dims(img, -1)\n",
        "                X_data[i] = img\n",
        "                Y_data[i, :len(text)] = text_to_labels(text)\n",
        "                label_length[i] = len(text)\n",
        "                \n",
        "            inputs = {\n",
        "                'the_input': X_data,\n",
        "                'the_labels': Y_data,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "            }\n",
        "            outputs = {'ctc': np.zeros([self.batch_size])}\n",
        "            yield (inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-JKOGglTztY",
        "colab_type": "text"
      },
      "source": [
        "### Train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzf4l7nFTajS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from Parameter import *\n",
        "#from ImageGenerator import TextImageGenerator\n",
        "#from CRNN_Model import word_model, line_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from Utils import *\n",
        "\n",
        "\n",
        "def train(train_list, val_list, is_word_model):\n",
        "    if is_word_model:\n",
        "        input_length = 32 - 2\n",
        "        model, _ = word_model()\n",
        "        model_name = 'iam_words'\n",
        "        max_text_len = 16\n",
        "    else:\n",
        "        input_length = 100 - 2\n",
        "        model, _ = line_model()\n",
        "        model_name = 'iam_line'\n",
        "        max_text_len = 74\n",
        "\n",
        "    batch_size = 32\n",
        "    img_w = 128\n",
        "    img_h = 64\n",
        "    train_set = TextImageGenerator(train_list, img_w, img_h, batch_size, input_length, max_text_len)\n",
        "    print('Loading data for train ...')\n",
        "    train_set.build_data()\n",
        "    val_set = TextImageGenerator(val_list, img_w, img_h, batch_size, input_length, max_text_len)\n",
        "    val_set.build_data()\n",
        "    print('Done')\n",
        "    \n",
        "    no_train_set = train_set.n\n",
        "    no_val_set = val_set.n\n",
        "    print(\"Number train set: \", no_train_set)\n",
        "    print(\"Number val set: \", no_val_set)\n",
        "    \n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')\n",
        "\n",
        "    ckp = ModelCheckpoint(\n",
        "        filepath=model_name+'--{epoch:02d}--{val_loss:.3f}.h5', monitor='val_loss',\n",
        "        verbose=1, save_best_only=True, save_weights_only=True\n",
        "    )\n",
        "    earlystop = EarlyStopping(\n",
        "        monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'\n",
        "    )\n",
        "\n",
        "    model.fit_generator(generator=train_set.next_batch(),\n",
        "                        steps_per_epoch=no_train_set // batch_size,\n",
        "                        epochs=32,\n",
        "                        validation_data=val_set.next_batch(),\n",
        "                        validation_steps=no_val_set // batch_size,\n",
        "                        callbacks=[ckp, earlystop])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpKj4gjwUTCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "if __name__=='__main__':\n",
        "    paths_and_texts = get_paths_and_texts()\n",
        "    print('number of image: ', len(paths_and_texts))\n",
        "\n",
        "    paths_and_texts_train, paths_and_texts_test = train_test_split(paths_and_texts, test_size=0.4, random_state=1707)\n",
        "    paths_and_texts_val, paths_and_texts_test = train_test_split(paths_and_texts_test, test_size=0.5, random_state=1707)\n",
        "    print('number of train image: ', len(paths_and_texts_train))\n",
        "    print('number of valid image: ', len(paths_and_texts_val))\n",
        "    print('number of test image: ', len(paths_and_texts_test))\n",
        "\n",
        "    model = train(paths_and_texts_train, paths_and_texts_val, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvUZ5tLMzN4c",
        "colab_type": "code",
        "outputId": "cd05f624-cd73-4591-814a-c7a1dc3eb51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "paths_and_texts = get_paths_and_texts(True)\n",
        "print('number of image: ', len(paths_and_texts))\n",
        "paths_and_texts_train, paths_and_texts_test = train_test_split(paths_and_texts, test_size=0.4, random_state=1707)\n",
        "paths_and_texts_val, paths_and_texts_test = train_test_split(paths_and_texts_test, test_size=0.5, random_state=1707)\n",
        "print('number of train image: ', len(paths_and_texts_train))\n",
        "print('number of valid image: ', len(paths_and_texts_val))\n",
        "print('number of test image: ', len(paths_and_texts_test))\n",
        "model = train(paths_and_texts_train, paths_and_texts_val, True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of image:  96456\n",
            "number of train image:  57873\n",
            "number of valid image:  19291\n",
            "number of test image:  19292\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 128, 64, 64)  256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 64, 64)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 32, 128)  512         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 32, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 16, 256)  1024        conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 16, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 16, 256)  1024        conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 16, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 8, 512)   2048        conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 8, 512)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 8, 512)   2048        conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 8, 512)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 4, 512)   2048        con7[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 4, 512)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 2048)     0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 32, 256)      246528      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 32, 256)      246528      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 32, 256)      0           gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 256)      0           gru1[0][0]                       \n",
            "                                                                 lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 256)      1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 32, 256)      393984      batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 32, 256)      393984      batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 32, 256)      0           gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 512)      0           gru2[0][0]                       \n",
            "                                                                 lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 32, 512)      2048        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 32, 80)       41040       batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 7,014,032\n",
            "Trainable params: 7,008,016\n",
            "Non-trainable params: 6,016\n",
            "__________________________________________________________________________________________________\n",
            "Loading data for train ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnoYOvg9UXXG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zC2eGQPagim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras \n",
        "loaded_model = keras.models.load_model('/content/drive/My Drive/keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfTaPL_4agaE",
        "colab_type": "code",
        "outputId": "65518b6d-82c5-4d96-ce52-3baeb57945a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def predict_image(model_predict, path, is_word):\n",
        "    if is_word:\n",
        "        width = 128\n",
        "    else:\n",
        "        width = 800\n",
        "    img = preprocess(path, width, 64)\n",
        "    img = img.T\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        img = np.expand_dims(img, 0)\n",
        "    else:\n",
        "        img = np.expand_dims(img, -1)\n",
        "    img = np.expand_dims(img, 0)\n",
        "\n",
        "    net_out_value = model_predict.predict(img)\n",
        "    pred_texts = decode_label(net_out_value)\n",
        "    return pred_texts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor 'softmax/truediv:0' shape=(?, 32, 80) dtype=float32>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siqAtAsOagV4",
        "colab_type": "code",
        "outputId": "aaf8d71e-1457-4113-c1de-3137184455c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img = preprocess('/content/drive/My Drive/Downloads/iam_words/words/a01/a01-000u/a01-000u-00-01.png',128,64)\n",
        "type(img), img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (64, 128))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWAzT9SYagSV",
        "colab_type": "code",
        "outputId": "855eaccb-33a1-454e-b40e-efa39138582e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img = img.T\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi0MQpnZagQt",
        "colab_type": "code",
        "outputId": "e4fe1d2c-eb1d-4612-92a3-2cd8a50c3da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img = np.expand_dims(img,-1)\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq_5--gwdH8U",
        "colab_type": "code",
        "outputId": "d5eb093e-a767-43b3-c06b-55c413870051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img = np.expand_dims(img , 0)\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PCIyYcoagMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net_out_value = loaded_model.predict(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHtyt-UYagKI",
        "colab_type": "code",
        "outputId": "0aca9cbc-7523-4c7f-c2ec-7998adda62d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net_out_value.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 32, 80)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVdOTDJQdifO",
        "colab_type": "code",
        "outputId": "36360cdc-affc-41a2-9911-61e6b2c525b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "net_out_value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.56408521e-06, 5.57086288e-09, 3.89102723e-08, ...,\n",
              "         3.66089878e-08, 1.51185219e-07, 5.32454109e-17],\n",
              "        [8.37857669e-07, 3.03258374e-09, 1.65351519e-08, ...,\n",
              "         2.10945945e-08, 7.56529559e-08, 2.46695897e-17],\n",
              "        [2.65278845e-06, 1.63754454e-10, 2.19709095e-09, ...,\n",
              "         8.46826220e-10, 1.12611644e-08, 5.67723251e-16],\n",
              "        ...,\n",
              "        [3.09416892e-09, 6.91880220e-10, 1.61078805e-13, ...,\n",
              "         5.87913846e-14, 1.36801473e-10, 9.99930978e-01],\n",
              "        [1.33054954e-07, 1.01938431e-08, 4.09885190e-12, ...,\n",
              "         1.02376302e-11, 6.65892674e-10, 9.55144167e-01],\n",
              "        [2.76119209e-07, 1.47372461e-07, 7.40479233e-10, ...,\n",
              "         1.95159133e-09, 2.03374739e-09, 6.53039024e-04]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruQSRPvsagGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py    \n",
        "import numpy as np    \n",
        "f1 = h5py.File('/content/drive/My Drive/keras_model.h5','r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcvDfNCGagEC",
        "colab_type": "code",
        "outputId": "79778223-2506-4665-b090-157acdcc6eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(f1.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_weights']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaAZsrYhjEnt",
        "colab_type": "code",
        "outputId": "9bdad16f-1cfd-4096-a5f5-ae773515959b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "list(f1['model_weights'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['activation_1',\n",
              " 'activation_2',\n",
              " 'activation_3',\n",
              " 'activation_4',\n",
              " 'activation_5',\n",
              " 'activation_6',\n",
              " 'activation_7',\n",
              " 'add_1',\n",
              " 'batch_normalization_1',\n",
              " 'batch_normalization_2',\n",
              " 'batch_normalization_3',\n",
              " 'batch_normalization_4',\n",
              " 'batch_normalization_5',\n",
              " 'batch_normalization_6',\n",
              " 'batch_normalization_7',\n",
              " 'batch_normalization_8',\n",
              " 'batch_normalization_9',\n",
              " 'con7',\n",
              " 'concatenate_1',\n",
              " 'conv1',\n",
              " 'conv2',\n",
              " 'conv3',\n",
              " 'conv4',\n",
              " 'conv5',\n",
              " 'conv6',\n",
              " 'dense1',\n",
              " 'dense2',\n",
              " 'gru1',\n",
              " 'gru1_b',\n",
              " 'gru2',\n",
              " 'gru2_b',\n",
              " 'lambda_1',\n",
              " 'lambda_2',\n",
              " 'max1',\n",
              " 'max2',\n",
              " 'max3',\n",
              " 'max4',\n",
              " 'reshape',\n",
              " 'softmax',\n",
              " 'the_input']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJn6-PZragB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6C8VFCittJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIC7GDi7itqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_u6iZ4OitnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XajjuF5Ty16M",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ-XSqaUXS4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model_file(\"/content/drive/My Drive/keras_model.h5\")\n",
        "tflite_model = converter.convert()\n",
        "open(\"/content/drive/My Drive/keras_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utezv9DwXSiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPGHIi9eXSeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqX5MavAXSZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxMm-zivU5Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "with open('/content/drive/My Drive/Downloads/word_model_predict.json', 'r') as f:\n",
        "\t\tmodel = model_from_json(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqf3eEtKZLLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, model = word_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOxhyLrBcP1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/Downloads/iam_words--15--1.791.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBdPhbQ3cmLi",
        "colab_type": "code",
        "outputId": "b07a207f-0116-4000-b39e-e7f4863bee66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predict_image(model, '/content/drive/My Drive/Downloads/iam_words/words/a01/a01-000u/a01-000u-00-01.png', is_word=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'MOVE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZvO0xOq7_l1",
        "colab_type": "code",
        "outputId": "1473a289-8d8f-4e1e-852d-fb8e5d33a605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 64, 64)  256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 64, 64)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 32, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 16, 256)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 8, 512)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "con7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 4, 512)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 2048)     0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 32, 256)      246528      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 32, 256)      246528      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 32, 256)      0           gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 256)      0           gru1[0][0]                       \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 256)      1024        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 32, 256)      393984      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 32, 256)      393984      batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 256)      0           gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 512)      0           gru2[0][0]                       \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 512)      2048        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 32, 80)       41040       batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 32, 80)       0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 7,014,032\n",
            "Trainable params: 7,008,016\n",
            "Non-trainable params: 6,016\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLshrni87JNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "keras_file = \"/content/drive/My Drive/keras_model.h5\"\n",
        "model.save(keras_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsxC3l_f7Std",
        "colab_type": "code",
        "outputId": "b78a59c1-ac3f-4d14-8a09-df6e1573c416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loaded_model.layers[1].get_weights()[0][0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtBSIQgn929L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "loaded_model = keras.models.load_model('/content/drive/My Drive/keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSc_waWfzOBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDKfZsUs97rj",
        "colab_type": "code",
        "outputId": "f4d3e33d-ba7f-4de9-fbb5-2f83b41299ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "predict_image(loaded_model, '/content/drive/My Drive/Downloads/iam_words/words/a01/a01-000u/a01-000u-01-06.png', is_word=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cd72d4a00e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/Downloads/iam_words/words/a01/a01-000u/a01-000u-01-06.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'predict_image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdYE7VgKUkye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOFH2vn--E6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_names = [node.op.name for node in loaded_model.inputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyJsncqLbiQb",
        "colab_type": "code",
        "outputId": "a40e74ec-6c46-42d7-b352-550371d25643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loaded_model.inputs[0].op.name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the_input'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKW5GOlVbfa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[node.op.name for node in loaded_model.inputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGY8g30jVk2a",
        "colab_type": "code",
        "outputId": "a5972e5c-e4c0-4dcd-8cc7-54e1243415b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the_input']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdB81damVkk5",
        "colab_type": "code",
        "outputId": "08b3c5ec-2e0b-47b7-c891-117e0ed0c454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m_output_names = [node.op.name for node in model.outputs]\n",
        "m_output_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['softmax_1/truediv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etERMgl4VuVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_sess = tf.keras.backend.get_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZzgUxlNV08D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_frozen_def = tf.graph_util.convert_variables_to_constants(m_sess, m_sess.graph_def, m_output_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFcLJ7GCVkUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsO5b8pGU1NN",
        "colab_type": "code",
        "outputId": "88171642-02b2-4dbc-f49f-571847cb7794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "sess = tf.keras.backend.get_session()\n",
        "sess"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.client.session.Session at 0x7f533eedf198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXHTKddwU5-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frozen_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, output_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brwxFB4aVLik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}